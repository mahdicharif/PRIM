{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Graph Networkdisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will provide a short presentation of my work. It led me to create a graph, stored on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"C:/Users/chari/networkdisk/\")\n",
    "import networkdisk as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion function (for lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_array(blob):\n",
    "    return json.loads(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(path = \"\"):\n",
    "\n",
    "    start = time.process_time()\n",
    "\n",
    "    sqlite3.register_converter('array', convert_array)\n",
    "    con = sqlite3.connect(path + \"articles_data.db\", detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "\n",
    "    cu = con.cursor()\n",
    "    qu = \"SELECT Name_article, Links FROM Article\"\n",
    "    pe = list(cu.execute(qu))\n",
    "\n",
    "    pe = [(node1, element) for node1, l in pe for element in l]\n",
    "    length = len(pe)\n",
    "\n",
    "    print(\"The data has been imported after {} seconds\".format(time.process_time() - start))\n",
    "    print(\"Its length is {}\".format(length))\n",
    "    \n",
    "    G = nd.sqlite.DiGraph(db=path + \"digraph.db\", nom=\"A\", insert_schema=True, sql_logger=True)\n",
    "\n",
    "    ind = 80000000\n",
    "    next_i = 0\n",
    "    \n",
    "    while next_i < length: # length of the whole db\n",
    "\n",
    "        print(\"beginning to insert the next 80 000 000 edges\")\n",
    "\n",
    "        start = time.process_time()\n",
    "        \n",
    "        dat = pe[next_i:ind]\n",
    "\n",
    "        print(\"data loaded\")\n",
    "\n",
    "        G.add_edges_from(dat)\n",
    "\n",
    "        print(\"{} edges have been added\".format(ind))\n",
    "        print(\"after {} seconds\".format(time.process_time() - start))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        ind += 80000000\n",
    "        next_i += 80000000\n",
    "        dat = None\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    G.helper.db.close()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph(\"/data/name_user/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went over the database of articles by slices of 80.000.000 edges. It enabled me not to provide the whole set of edges (around 300 million) all at once to Networkdisk. \n",
    "\n",
    "The process took about 4h to complete. The result is a database, named *digraph.db*, in which are stored the nodes and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nd.sqlite.DiGraph(db = \"D:/XML/data/digraph.db\", nom=\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_usa = list(G[\"United States\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I retrieved the edges linked to a big page : the one about the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Blakeley', '#Boyer', '#Davis96', '#Daynes', '#Ferguson']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_usa[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to figure out which shortest path we can get between two nodes. Networkx will be used to perform that task.\n",
    "\n",
    "Node_a will be \"United States\" and node_b will be \"France\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States', 'Aaron Copland', 'France']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.shortest_path(G, \"United States\", \"France\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
